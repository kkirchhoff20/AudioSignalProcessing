{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "405b8672",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import signal\n",
    "from scipy.io import wavfile\n",
    "import sunau\n",
    "from scipy import signal\n",
    "from scipy.io import wavfile\n",
    "import pandas as pd\n",
    "import pywt\n",
    "import librosa\n",
    "import python_speech_features\n",
    "from sklearn.utils.validation import check_X_y, check_array, check_is_fitted\n",
    "import pywt # Python wavelet transform implementation\n",
    "from sklearn.base import BaseEstimator, TransformerMixin # Interfaces and base classes for pipeline components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dba6783d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Normalizer(TransformerMixin, BaseEstimator):\n",
    "    \"\"\"\n",
    "    Normalizes sample data to the interval (-1, 1)\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    \n",
    "    \"\"\"\n",
    "    def __init__(self, nbits: int, signed: bool):\n",
    "        self.signed = signed\n",
    "        self.nbits = nbits\n",
    "        if self.signed:\n",
    "            self.nbits = self.nbits-1\n",
    "    \n",
    "    def transform(self, samples: np.array) -> np.array:\n",
    "        normalized_samples = samples/(2**self.nbits) \n",
    "        normalized_samples = np.clip(normalized_samples, -1, 1)\n",
    "        return normalized_samples\n",
    "    \n",
    "    def fit(self, X):\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6d53a015",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NormFFT(TransformerMixin, BaseEstimator):\n",
    "    \n",
    "    def __init__(self, n: int = 5000):\n",
    "        self.n=n\n",
    "        \n",
    "    def transform(self, normalized_samples: np.array) -> (np.array, np.array, np.array):\n",
    "        transformed_samples = fft(normalized_samples, n=self.n) # calculate fourier transform (complex numbers list)\n",
    "        length = len(transformed_samples)/2  # you only need half of the fft list (real signal symmetry)\n",
    "        halved_transform = transformed_samples[0:int(length-1)]\n",
    "        return np.abs(halved_transform), np.real(halved_transform), np.imag(halved_transform) \n",
    "    \n",
    "    def fit(self, X):\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "72b782d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils.validation import check_X_y, check_array, check_is_fitted\n",
    "import pywt # Python wavelet transform implementation\n",
    "from sklearn.base import BaseEstimator, TransformerMixin # Interfaces and base classes for pipeline components\n",
    "class WaveletTransformer(TransformerMixin, BaseEstimator):\n",
    "    \"\"\"Compute approximation coefficients of a selected wavelet.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    wavelet_name : str, default='db1'\n",
    "        Wavelet to use in transformation.\n",
    "        Must be a wavelet name defiend in PyWavelets library\n",
    "        See http://wavelets.pybytes.com/\n",
    "    mode : str, default='symmetric'\n",
    "        Extrapolation mode for transform.\n",
    "        See https://pywavelets.readthedocs.io/en/latest/ref/signal-extension-modes.html#ref-modes\n",
    "    Attributes\n",
    "    ----------\n",
    "    n_features_ : int\n",
    "        The number of features of the data passed to :meth:`fit`.\n",
    "    wavelet_name : str, default='db1'\n",
    "        Wavelet to use in transformation.\n",
    "        See http://wavelets.pybytes.com/\n",
    "    mode : str, default='symmetric'\n",
    "        Extrapolation mode for transform.\n",
    "        See https://pywavelets.readthedocs.io/en/latest/ref/signal-extension-modes.html#ref-modes\n",
    "    \n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 wavelet_name: str = 'db1',\n",
    "                 mode: str = 'symmetric'):\n",
    "        self.wavelet_name = wavelet_name\n",
    "        self.mode = mode\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        \"\"\"A reference implementation of a fitting function for a transformer.\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : {array-like, sparse matrix}, shape (n_samples, n_features)\n",
    "            The training input samples.\n",
    "        y : None\n",
    "            There is no need of a target in a transformer, yet the pipeline API\n",
    "            requires this parameter.\n",
    "        Returns\n",
    "        -------\n",
    "        self : object\n",
    "            Returns self.\n",
    "        \"\"\"\n",
    "        X = check_array(X, accept_sparse=True)\n",
    "\n",
    "        # Each row of X must have the same length\n",
    "        # In other words, signals need to be truncated or padded to a fixed length\n",
    "        # prior to passing to this transformer.\n",
    "        self.n_features_ = X.shape[1]\n",
    "\n",
    "        # Other checks go here\n",
    "        \n",
    "        # Return the transformer\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        \"\"\" Compute wavelet transform on input data X\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        X : {array-like, sparse-matrix}, shape (n_samples, n_features)\n",
    "            The input samples.\n",
    "        Returns\n",
    "        -------\n",
    "        X_transformed : array, shape (n_samples, n_features)\n",
    "            The array containing the wavelet transform approximation coefficients from each row of X\n",
    "            in ``X``.\n",
    "        \"\"\"\n",
    "        # Check is fit had been called\n",
    "        check_is_fitted(self, 'n_features_')\n",
    "\n",
    "        # Input validation\n",
    "        X = check_array(X, accept_sparse=True)\n",
    "\n",
    "        # Check that the input is of the same shape as the one passed\n",
    "        # during fit.\n",
    "        if X.shape[1] != self.n_features_:\n",
    "            raise ValueError('Shape of input is different from what was seen'\n",
    "                             'in `fit`')\n",
    "            \n",
    "        (cA, cD) = pywt.dwt(X, self.wavelet_name, self.mode)\n",
    "        return cA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b483c011",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadAudio(audioPath):\n",
    "    sample_rate, samples = wavfile.read(audioPath)\n",
    "    frequencies, times, spectrogram = signal.spectrogram(samples, sample_rate)\n",
    "    spectrogram = np.log(spectrogram)\n",
    "    transposed_spec = spectrogram.transpose()\n",
    "    freq_list = list(frequencies)\n",
    "    #freq_list = [str(f) for f in freq_list]\n",
    "    #freq_list = [f + \" Hz\" for f in freq_list]\n",
    "    audio_df = pd.DataFrame(transposed_spec, index = times, columns = freq_list )\n",
    "    audio_df.index = times\n",
    "    audio_df\n",
    "    return audio_df, samples, sample_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e46ff291",
   "metadata": {},
   "outputs": [],
   "source": [
    "def constructSpectrogramFigure(audio_df):\n",
    "    fig, ax = plt.subplots(figsize=(16, 4))\n",
    "    im = plt.pcolormesh(audio_df.index, audio_df.columns, audio_df.transpose(), shading='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "6804d21f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "- A function to normalize a wave\n",
    "- A function that computes an FFT given a normalized wave, then takes the first half, then returns the magnitude or real or complex part\n",
    "    - Either accept a normalized wave or call the normalize function on raw wave\n",
    "- A function to plot the FFT\n",
    "    - Either pass the FFT as a argument or normalized wave, or call FFT on raw wave, etc\n",
    "\"\"\"\n",
    "def normalize(samples: np.array) -> np.array:\n",
    "    normalized_samples = samples/(2**15) #b is now normalized on [-1,1) [we were going to normalize between -1,1 like they had, so we divide by the maximum value permitted by this number of bits (8, 16, 32, ..) minus 1 (for the signed bit)]\n",
    "    normalized_samples = np.clip(normalized_samples, -1, 1)\n",
    "    return normalized_samples\n",
    "\n",
    "def normFFT(normalized_samples: np.array, n: int =5000) -> (np.array, np.array, np.array):\n",
    "    \"\"\"This function takes a normalized numpy array of amplitude measurements, applies a FFT, and returns the magnitudes,\n",
    "        the real parts, and the imaginary parts of the FFT\n",
    "    \n",
    "    Inputs:\n",
    "        normalized_samples (np.array): an array of floats bounded between -1 and 1\n",
    "        n: (int): output length for FFT; the length of the resulting arrays will be n/2\n",
    "    Returns:\n",
    "        tuple: numpy arrays of the magnitudes of the FFT, the real parts of the FFT, the imaginary parts of the FFT\n",
    "    \"\"\"\n",
    "    transformed_samples = fft(normalized_samples, n=n) # calculate fourier transform (complex numbers list)\n",
    "    length = len(transformed_samples)/2  # you only need half of the fft list (real signal symmetry)\n",
    "    #halved_transform = transformed_samples[0:int(length-1)]\n",
    "    #return np.abs(halved_transform), np.real(halved_transform), np.imag(halved_transform)\n",
    "    return np.abs(transformed_samples), np.real(transformed_samples), np.imag(transformed_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "ce187558",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.fftpack import fft\n",
    "def constructFFTFigure(abs_fft):\n",
    "    plt.plot(abs_fft) \n",
    "    plt.xlim((0,1000))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "af43f28b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.signal import butter,filtfilt\n",
    "def butter_highpass_filter(data, cutoff, sample_rate, order):\n",
    "    normal_cutoff = cutoff / (0.5 * sample_rate)\n",
    "    # Get the filter coefficients \n",
    "    b, a = butter(order, normal_cutoff, btype='high', analog=False)\n",
    "    y = filtfilt(b, a, data)\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "11973e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "def butter_lowpass_filter(data, cutoff, sample_rate, order):\n",
    "    normal_cutoff = cutoff / (0.5 * sample_rate)\n",
    "    # Get the filter coefficients \n",
    "    b, a = butter(order, normal_cutoff, btype='low', analog=False)\n",
    "    y = filtfilt(b, a, data)\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "a1bcfd1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#delet above\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "122ed06d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['C:\\\\Users\\\\kbk17\\\\EspionageDomainExploration\\\\backgroundnoisewithcar.wav',\n",
       " 'C:\\\\Users\\\\kbk17\\\\EspionageDomainExploration\\\\desk_tap1.wav',\n",
       " 'C:\\\\Users\\\\kbk17\\\\EspionageDomainExploration\\\\desk_tap2.wav',\n",
       " 'C:\\\\Users\\\\kbk17\\\\EspionageDomainExploration\\\\desk_tap3.wav',\n",
       " 'C:\\\\Users\\\\kbk17\\\\EspionageDomainExploration\\\\desk_tap4.wav',\n",
       " 'C:\\\\Users\\\\kbk17\\\\EspionageDomainExploration\\\\desk_tap5.wav',\n",
       " 'C:\\\\Users\\\\kbk17\\\\EspionageDomainExploration\\\\desk_tap6.wav',\n",
       " 'C:\\\\Users\\\\kbk17\\\\EspionageDomainExploration\\\\desk_tap7.wav',\n",
       " 'C:\\\\Users\\\\kbk17\\\\EspionageDomainExploration\\\\desk_tap8.wav',\n",
       " 'C:\\\\Users\\\\kbk17\\\\EspionageDomainExploration\\\\desk_taps.wav',\n",
       " 'C:\\\\Users\\\\kbk17\\\\EspionageDomainExploration\\\\key_press1.wav',\n",
       " 'C:\\\\Users\\\\kbk17\\\\EspionageDomainExploration\\\\key_press2.wav',\n",
       " 'C:\\\\Users\\\\kbk17\\\\EspionageDomainExploration\\\\key_press3.wav',\n",
       " 'C:\\\\Users\\\\kbk17\\\\EspionageDomainExploration\\\\key_press4.wav',\n",
       " 'C:\\\\Users\\\\kbk17\\\\EspionageDomainExploration\\\\key_press5.wav',\n",
       " 'C:\\\\Users\\\\kbk17\\\\EspionageDomainExploration\\\\key_presses.wav']"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glob.glob(\"C:\\\\Users\\\\kbk17\\\\EspionageDomainExploration\\\\*.wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "0f456e82",
   "metadata": {},
   "outputs": [],
   "source": [
    "desk_path_list = ['C:\\\\Users\\\\kbk17\\\\EspionageDomainExploration\\\\desk_tap1.wav',\n",
    "                     'C:\\\\Users\\\\kbk17\\\\EspionageDomainExploration\\\\desk_tap2.wav',\n",
    "                     'C:\\\\Users\\\\kbk17\\\\EspionageDomainExploration\\\\desk_tap3.wav',\n",
    "                     'C:\\\\Users\\\\kbk17\\\\EspionageDomainExploration\\\\desk_tap4.wav',\n",
    "                     'C:\\\\Users\\\\kbk17\\\\EspionageDomainExploration\\\\desk_tap5.wav',\n",
    "                     'C:\\\\Users\\\\kbk17\\\\EspionageDomainExploration\\\\desk_tap6.wav',\n",
    "                     'C:\\\\Users\\\\kbk17\\\\EspionageDomainExploration\\\\desk_tap7.wav',\n",
    "                     'C:\\\\Users\\\\kbk17\\\\EspionageDomainExploration\\\\desk_tap8.wav']\n",
    "key_path_list = ['C:\\\\Users\\\\kbk17\\\\EspionageDomainExploration\\\\key_press1.wav',\n",
    "                 'C:\\\\Users\\\\kbk17\\\\EspionageDomainExploration\\\\key_press2.wav',\n",
    "                 'C:\\\\Users\\\\kbk17\\\\EspionageDomainExploration\\\\key_press3.wav',\n",
    "                 'C:\\\\Users\\\\kbk17\\\\EspionageDomainExploration\\\\key_press4.wav',\n",
    "                 'C:\\\\Users\\\\kbk17\\\\EspionageDomainExploration\\\\key_press5.wav']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "939c573b",
   "metadata": {},
   "outputs": [],
   "source": [
    "desk_read_output = [loadAudio(x) for x in desk_path_list] #a list of tuples of spectrogram (a dataframe whose columns are frequencies, rows are points in time, values are magnitudes of freqs), numpy array (raw audio data), and an int\n",
    "key_read_output = [loadAudio(x) for x in key_path_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "0205c523",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nHousing Price Estimator\\n\\nY ~ X1 + X2 + X3\\n\\nY  | X1 | X2 | X3\\n----------------\\n600k| 3  | 40 | 53\\n300k| 2  | 20 | 70\\n   \\nSound Classifier\\n\\nY | Hz_1_1 | Hz_2_1 | ... | Hz_1_2 | Hz_2_2 | .... \\n-----------------\\nD |\\nK |\\n'"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Housing Price Estimator\n",
    "\n",
    "Y ~ X1 + X2 + X3\n",
    "\n",
    "Y  | X1 | X2 | X3\n",
    "----------------\n",
    "600k| 3  | 40 | 53\n",
    "300k| 2  | 20 | 70\n",
    "   \n",
    "Sound Classifier\n",
    "\n",
    "Y | Hz_1_1 | Hz_2_1 | ... | Hz_1_2 | Hz_2_2 | .... \n",
    "-----------------\n",
    "D |\n",
    "K |\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7006ca1a",
   "metadata": {},
   "source": [
    "# This is for the real part of the FFT only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "be38d2e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = []\n",
    "waveforms = []\n",
    "for df, samples, sample_rate in key_read_output:\n",
    "    waveforms.append(samples)\n",
    "    labels.append(0)\n",
    "    \n",
    "for df, samples, sample_rate in desk_read_output:\n",
    "    waveforms.append(samples)\n",
    "    labels.append(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "5dd421e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14262"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "longest = 0\n",
    "for w in waveforms:\n",
    "    if len(w) > longest:\n",
    "        longest=len(w)\n",
    "longest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "fe335490",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_samples = [normalize(sample) for sample in waveforms]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "8556c1ab",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'halved_transform' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_9780/3457911171.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#each component in this list is a tuple composed of magnitudes, real parts, and imaginary parts\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mffts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mnormFFT\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlongest\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mnormalized_samples\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_9780/3457911171.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#each component in this list is a tuple composed of magnitudes, real parts, and imaginary parts\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mffts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mnormFFT\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlongest\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mnormalized_samples\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_9780/468295528.py\u001b[0m in \u001b[0;36mnormFFT\u001b[1;34m(normalized_samples, n)\u001b[0m\n\u001b[0;32m     25\u001b[0m     \u001b[0mlength\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtransformed_samples\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m2\u001b[0m  \u001b[1;31m# you only need half of the fft list (real signal symmetry)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m     \u001b[1;31m#halved_transform = transformed_samples[0:int(length-1)]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhalved_transform\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhalved_transform\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimag\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhalved_transform\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'halved_transform' is not defined"
     ]
    }
   ],
   "source": [
    "#each component in this list is a tuple composed of magnitudes, real parts, and imaginary parts\n",
    "ffts = [normFFT(w, longest) for w in normalized_samples]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "84378d5a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[7130, 7130, 7130, 7130, 7130, 7130, 7130, 7130, 7130, 7130, 7130, 7130, 7130]"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[len(x[0]) for x in ffts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "6937989d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13, 7130)"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tuple components\n",
    "magnitudes = 0\n",
    "real_part = 1\n",
    "imag_part = 2\n",
    "\n",
    "X_train = np.vstack([t[real_part] for t in ffts])\n",
    "# 0 corresponds to keypress, 1 to desktap\n",
    "y_train = labels\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "a6036b43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 5.38963135e+02, -8.99767698e+02,  1.73396474e+03, ...,\n",
       "         4.21634589e-02,  1.07224755e-01, -1.90448170e-01],\n",
       "       [-5.23357330e+02, -6.63200249e+02,  7.19952731e+02, ...,\n",
       "        -6.67591015e-02,  2.30031218e-02,  1.62695051e-01],\n",
       "       [-1.41549744e+02, -3.16605433e+02,  3.24055513e+02, ...,\n",
       "         9.41471700e-02, -1.75952324e-01, -2.09322989e-01],\n",
       "       ...,\n",
       "       [-2.39297485e+00,  1.20429282e+00, -2.47457103e+01, ...,\n",
       "         3.82669127e-02, -5.99555191e-03,  2.12888799e-02],\n",
       "       [-3.56314087e+00,  3.67538406e+01,  3.99749760e+01, ...,\n",
       "         6.17863378e-03, -2.58381612e-02, -1.89590677e-02],\n",
       "       [-2.75354004e+00,  2.72658809e+01, -1.82402099e+01, ...,\n",
       "         1.36899091e-02, -3.65458315e-02, -7.84401260e-04]])"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "77b28281",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('minmaxscaler', MinMaxScaler()),\n",
       "                ('svc', SVC(gamma='auto', kernel='linear'))])"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.svm import SVC\n",
    "clf = make_pipeline(MinMaxScaler(), SVC(gamma='auto', kernel='linear'))\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "fe0e5886",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "5ab6a4fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('minmaxscaler', MinMaxScaler()),\n",
       "                ('logisticregression', LogisticRegression())])"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "lr_clf = make_pipeline(MinMaxScaler(), LogisticRegression())\n",
    "lr_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "b775a505",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_clf.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "4d07a6bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['C:\\\\Users\\\\kbk17\\\\EspionageDomainExploration\\\\Test_Cases\\\\Audio Track-10.wav',\n",
       " 'C:\\\\Users\\\\kbk17\\\\EspionageDomainExploration\\\\Test_Cases\\\\Audio Track-11.wav',\n",
       " 'C:\\\\Users\\\\kbk17\\\\EspionageDomainExploration\\\\Test_Cases\\\\Audio Track-12.wav',\n",
       " 'C:\\\\Users\\\\kbk17\\\\EspionageDomainExploration\\\\Test_Cases\\\\Audio Track-13.wav',\n",
       " 'C:\\\\Users\\\\kbk17\\\\EspionageDomainExploration\\\\Test_Cases\\\\Audio Track-14.wav',\n",
       " 'C:\\\\Users\\\\kbk17\\\\EspionageDomainExploration\\\\Test_Cases\\\\Audio Track-15.wav',\n",
       " 'C:\\\\Users\\\\kbk17\\\\EspionageDomainExploration\\\\Test_Cases\\\\Audio Track-16.wav',\n",
       " 'C:\\\\Users\\\\kbk17\\\\EspionageDomainExploration\\\\Test_Cases\\\\Audio Track-17.wav',\n",
       " 'C:\\\\Users\\\\kbk17\\\\EspionageDomainExploration\\\\Test_Cases\\\\Audio Track-18.wav',\n",
       " 'C:\\\\Users\\\\kbk17\\\\EspionageDomainExploration\\\\Test_Cases\\\\Audio Track-19.wav',\n",
       " 'C:\\\\Users\\\\kbk17\\\\EspionageDomainExploration\\\\Test_Cases\\\\Audio Track-2.wav',\n",
       " 'C:\\\\Users\\\\kbk17\\\\EspionageDomainExploration\\\\Test_Cases\\\\Audio Track-20.wav',\n",
       " 'C:\\\\Users\\\\kbk17\\\\EspionageDomainExploration\\\\Test_Cases\\\\Audio Track-21.wav',\n",
       " 'C:\\\\Users\\\\kbk17\\\\EspionageDomainExploration\\\\Test_Cases\\\\Audio Track-3.wav',\n",
       " 'C:\\\\Users\\\\kbk17\\\\EspionageDomainExploration\\\\Test_Cases\\\\Audio Track-4.wav',\n",
       " 'C:\\\\Users\\\\kbk17\\\\EspionageDomainExploration\\\\Test_Cases\\\\Audio Track-5.wav',\n",
       " 'C:\\\\Users\\\\kbk17\\\\EspionageDomainExploration\\\\Test_Cases\\\\Audio Track-6.wav',\n",
       " 'C:\\\\Users\\\\kbk17\\\\EspionageDomainExploration\\\\Test_Cases\\\\Audio Track-7.wav',\n",
       " 'C:\\\\Users\\\\kbk17\\\\EspionageDomainExploration\\\\Test_Cases\\\\Audio Track-8.wav',\n",
       " 'C:\\\\Users\\\\kbk17\\\\EspionageDomainExploration\\\\Test_Cases\\\\Audio Track-9.wav',\n",
       " 'C:\\\\Users\\\\kbk17\\\\EspionageDomainExploration\\\\Test_Cases\\\\Audio Track.wav']"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_paths = glob.glob(\"C:\\\\Users\\\\kbk17\\\\EspionageDomainExploration\\\\Test_Cases\\\\*.wav\")\n",
    "test_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebe2c57d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "d1f8357a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_paths =[\n",
    "    'C:\\\\Users\\\\kbk17\\\\EspionageDomainExploration\\\\Test_Cases\\\\Audio Track.wav',\n",
    "    'C:\\\\Users\\\\kbk17\\\\EspionageDomainExploration\\\\Test_Cases\\\\Audio Track-2.wav',\n",
    "    'C:\\\\Users\\\\kbk17\\\\EspionageDomainExploration\\\\Test_Cases\\\\Audio Track-3.wav',\n",
    "    'C:\\\\Users\\\\kbk17\\\\EspionageDomainExploration\\\\Test_Cases\\\\Audio Track-4.wav',\n",
    "    'C:\\\\Users\\\\kbk17\\\\EspionageDomainExploration\\\\Test_Cases\\\\Audio Track-5.wav',\n",
    "    'C:\\\\Users\\\\kbk17\\\\EspionageDomainExploration\\\\Test_Cases\\\\Audio Track-6.wav',\n",
    "    'C:\\\\Users\\\\kbk17\\\\EspionageDomainExploration\\\\Test_Cases\\\\Audio Track-7.wav',\n",
    "    'C:\\\\Users\\\\kbk17\\\\EspionageDomainExploration\\\\Test_Cases\\\\Audio Track-8.wav',\n",
    "    'C:\\\\Users\\\\kbk17\\\\EspionageDomainExploration\\\\Test_Cases\\\\Audio Track-9.wav',\n",
    "    'C:\\\\Users\\\\kbk17\\\\EspionageDomainExploration\\\\Test_Cases\\\\Audio Track-10.wav',\n",
    "    'C:\\\\Users\\\\kbk17\\\\EspionageDomainExploration\\\\Test_Cases\\\\Audio Track-11.wav',\n",
    "    'C:\\\\Users\\\\kbk17\\\\EspionageDomainExploration\\\\Test_Cases\\\\Audio Track-12.wav',\n",
    "    'C:\\\\Users\\\\kbk17\\\\EspionageDomainExploration\\\\Test_Cases\\\\Audio Track-13.wav',\n",
    "    'C:\\\\Users\\\\kbk17\\\\EspionageDomainExploration\\\\Test_Cases\\\\Audio Track-14.wav',\n",
    "    'C:\\\\Users\\\\kbk17\\\\EspionageDomainExploration\\\\Test_Cases\\\\Audio Track-15.wav',\n",
    "    'C:\\\\Users\\\\kbk17\\\\EspionageDomainExploration\\\\Test_Cases\\\\Audio Track-16.wav',\n",
    "    'C:\\\\Users\\\\kbk17\\\\EspionageDomainExploration\\\\Test_Cases\\\\Audio Track-17.wav',\n",
    "    'C:\\\\Users\\\\kbk17\\\\EspionageDomainExploration\\\\Test_Cases\\\\Audio Track-18.wav',\n",
    "    'C:\\\\Users\\\\kbk17\\\\EspionageDomainExploration\\\\Test_Cases\\\\Audio Track-19.wav',\n",
    "    'C:\\\\Users\\\\kbk17\\\\EspionageDomainExploration\\\\Test_Cases\\\\Audio Track-20.wav',\n",
    "    'C:\\\\Users\\\\kbk17\\\\EspionageDomainExploration\\\\Test_Cases\\\\Audio Track-21.wav']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "11dfe132",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kbk17\\AppData\\Local\\Temp/ipykernel_9780/3106872685.py:2: WavFileWarning: Chunk (non-data) not understood, skipping it.\n",
      "  sample_rate, samples = wavfile.read(audioPath)\n"
     ]
    }
   ],
   "source": [
    "test_audio = [loadAudio(path) for path in test_paths]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "36f875b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_labels = []\n",
    "test_waveforms = []\n",
    "    \n",
    "for _, samples, _ in test_audio[0:6]:\n",
    "    test_waveforms.append(samples)\n",
    "    test_labels.append(0)\n",
    "\n",
    "for _, samples, _ in test_audio[6:12]:\n",
    "    test_waveforms.append(samples)\n",
    "    test_labels.append(1)\n",
    "\n",
    "len(test_waveforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "d62a2500",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'halved_transform' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_9780/3819919116.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mnormalized_test_waveforms\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mnormalize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtw\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mtw\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtest_waveforms\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mnormFFT_output\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mnormFFT\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mntw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlongest\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mntw\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mnormalized_test_waveforms\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_9780/3819919116.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mnormalized_test_waveforms\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mnormalize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtw\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mtw\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtest_waveforms\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mnormFFT_output\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mnormFFT\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mntw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlongest\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mntw\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mnormalized_test_waveforms\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_9780/468295528.py\u001b[0m in \u001b[0;36mnormFFT\u001b[1;34m(normalized_samples, n)\u001b[0m\n\u001b[0;32m     25\u001b[0m     \u001b[0mlength\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtransformed_samples\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m2\u001b[0m  \u001b[1;31m# you only need half of the fft list (real signal symmetry)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m     \u001b[1;31m#halved_transform = transformed_samples[0:int(length-1)]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhalved_transform\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhalved_transform\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimag\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhalved_transform\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'halved_transform' is not defined"
     ]
    }
   ],
   "source": [
    "normalized_test_waveforms = [normalize(tw) for tw in test_waveforms]\n",
    "normFFT_output = [normFFT(ntw, longest) for ntw in normalized_test_waveforms]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "0aebf814",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = np.vstack([ t[real_part] for t in normFFT_output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "91c105dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "4c4d87da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "cbe75c01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.02006929, 0.97993071],\n",
       "       [0.02088374, 0.97911626],\n",
       "       [0.02092747, 0.97907253],\n",
       "       [0.02093996, 0.97906004],\n",
       "       [0.02048695, 0.97951305],\n",
       "       [0.02084149, 0.97915851],\n",
       "       [0.02178763, 0.97821237],\n",
       "       [0.0222506 , 0.9777494 ],\n",
       "       [0.0198462 , 0.9801538 ],\n",
       "       [0.01699877, 0.98300123],\n",
       "       [0.00825823, 0.99174177],\n",
       "       [0.06059414, 0.93940586]])"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_clf.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae666896",
   "metadata": {},
   "source": [
    "# Experimenting with Real and Imaginary Parts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "58ce7a45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('minmaxscaler', MinMaxScaler()),\n",
       "                ('svc', SVC(gamma='auto', kernel='linear'))])"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = np.vstack([np.hstack([t[real_part], t[imag_part]]) for t in ffts])\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "10498346",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "7e04800e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = np.vstack([np.hstack([t[real_part], t[imag_part]]) for t in normFFT_output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "7d06e5e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d13fb920",
   "metadata": {},
   "source": [
    "# PCA of Fourier Domain Frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "47b5e362",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "d6d92467",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PCA(n_components=5)"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca = PCA(n_components = 5)\n",
    "pca.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "89917413",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.35345174 0.19366198 0.16024072 0.0706165  0.05051442]\n"
     ]
    }
   ],
   "source": [
    "print(pca.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "ec15eafd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('minmaxscaler', MinMaxScaler()), ('pca', PCA(n_components=8)),\n",
       "                ('logisticregression', LogisticRegression())])"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#this adds the steps we did above to the pipeline\n",
    "lr_clf = make_pipeline(MinMaxScaler(), PCA(n_components=8), LogisticRegression())\n",
    "lr_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "f80754fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9384313530472355"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_clf.named_steps['pca'].explained_variance_ratio_.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "01d49552",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9b35509",
   "metadata": {},
   "source": [
    "# Quick sanity check using Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "1ffa281e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "454cdd41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('minmaxscaler', MinMaxScaler()), ('pca', PCA(n_components=8)),\n",
       "                ('decisiontreeclassifier', DecisionTreeClassifier())])"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree_clf = make_pipeline(MinMaxScaler(), PCA(n_components=8), tree.DecisionTreeClassifier())\n",
    "tree_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "3844567a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree_clf.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "afc07e4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0])"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7f31261",
   "metadata": {},
   "source": [
    "# Retraining using all but two test data above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "a5e1d251",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('minmaxscaler', MinMaxScaler()), ('pca', PCA(n_components=8)),\n",
       "                ('decisiontreeclassifier', DecisionTreeClassifier())])"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree_clf.fit(X_train[1:9], y_train[1:9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "29dbeda4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree_clf.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "583be5e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70f49d60",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
